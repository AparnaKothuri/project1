{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Price Prediction — Complete Project\n",
    "This notebook was generated automatically. It unzips the uploaded project archive, loads the dataset, performs simple preprocessing, trains models (Linear Regression and Random Forest), evaluates them, and saves the best model.\n",
    "\n",
    "### What this notebook contains\n",
    "- Data loading & inspection\n",
    "- Simple EDA\n",
    "- Preprocessing pipeline (imputation, encoding, scaling)\n",
    "- Model training & evaluation\n",
    "- Save model\n",
    "\n",
    "Run the cells sequentially. If the dataset file location or column names differ, adjust the 'target' variable below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip status: Unzipped to /mnt/data/vehicle_price_prediction_extracted\n",
    "# Dataset search result: Found dataset: /mnt/data/vehicle_price_prediction_extracted/Vehicle Price Prediction/dataset.csv\n",
    "import os\n",
    "DATASET_PATH = \"/mnt/data/vehicle_price_prediction_extracted/Vehicle Price Prediction/dataset.csv\"\n",
    "print('DATASET_PATH =', DATASET_PATH)\n",
    "print('\\nFiles in extraction directory:')\n",
    "for root, dirs, files in os.walk('/mnt/data/vehicle_price_prediction_extracted'):\n",
    "    for f in files:\n",
    "        print(os.path.join(root, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if DATASET_PATH is None:\n",
    "    raise FileNotFoundError('No CSV dataset found in the extracted archive. Put your CSV in the zip and re-run upload.')\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print('Dataset shape:', df.shape)\n",
    "display(df.head())\n",
    "display(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple EDA\n",
    "import matplotlib.pyplot as plt\n",
    "print('Missing values per column:')\n",
    "print(df.isnull().sum())\n",
    "numeric = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "print('\\nNumeric columns:', numeric)\n",
    "print('\\nValue counts for top categorical columns:')\n",
    "cat = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "for c in cat[:5]:\n",
    "    print('\\n--', c)\n",
    "    print(df[c].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Modeling\n",
    "Assumptions:\n",
    "- The dataset contains a numeric target column representing price. **If your target column name is not `price`, update the `TARGET_COLUMN` variable** in the next cell.\n",
    "- We'll split features into numerical and categorical, impute missing values, encode categoricals with OneHotEncoder, scale numerical features, and train two models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# CHANGE THIS if your price column has a different name\n",
    "TARGET_COLUMN = 'price' if 'price' in df.columns else df.columns[-1]\n",
    "print('Using target column:', TARGET_COLUMN)\n",
    "\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models to try\n",
    "models = {\n",
    "    'LinearRegression': Pipeline(steps=[('preprocessor', preprocessor), ('reg', LinearRegression())]),\n",
    "    'RandomForest': Pipeline(steps=[('preprocessor', preprocessor), ('reg', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print('\\nTraining', name)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    results[name] = {'rmse': rmse, 'r2': r2, 'model': model}\n",
    "    print(f'{name} -> RMSE: {rmse:.4f}, R2: {r2:.4f}')\n",
    "\n",
    "# Choose best by RMSE\n",
    "best_name = min(results, key=lambda k: results[k]['rmse'])\n",
    "best_model = results[best_name]['model']\n",
    "print('\\nBest model:', best_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_path = '/mnt/data/best_vehicle_price_model.joblib'\n",
    "joblib.dump(best_model, model_path)\n",
    "print('Saved best model to', model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "best_preds = best_model.predict(X_test)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, best_preds, alpha=0.6)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted (Best Model)')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you have now\n",
    "- A runnable notebook that reads the dataset from the uploaded zip and trains models.\n",
    "- A saved model at `/mnt/data/best_vehicle_price_model.joblib`.\n",
    "\n",
    "If you want custom feature engineering, hyperparameter tuning, or a different target column name, edit the notebook cells accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_vehicle_price_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9482735d31b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_vehicle_price_model.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Example input — change values as per your dataset features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_vehicle_price_model.joblib'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(\"best_vehicle_price_model.joblib\")\n",
    "\n",
    "# Example input — change values as per your dataset features\n",
    "sample = pd.DataFrame({\n",
    "    'year': [2019],\n",
    "    'mileage': [30000],\n",
    "    'fuel_type': ['Petrol'],\n",
    "    'transmission': ['Manual']\n",
    "})\n",
    "\n",
    "# Predict vehicle price\n",
    "predicted_price = model.predict(sample)\n",
    "print(\"Predicted Vehicle Price:\", predicted_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
